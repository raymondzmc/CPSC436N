{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Language Model for CPSC 503 Assignment 2\n",
    "### This notebook is modified from Yunjey Choi's Github repository - pytorch-tutorial.\n",
    "### pytorch-tutorial/tutorials/02-intermediate/language_model/\n",
    "### https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/language_model\n",
    "\n",
    "### ========================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First of the first, let's load a number of dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cm/99gcnv6j23g23__vdsh2llrh0000gq/T/ipykernel_53459/4268023118.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are two classes needed for the data loading and formating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    # < MISSING CLASS DESCRIPTION >\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def return_dict(self):\n",
    "        return self.idx2word\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "\n",
    "class Corpus(object):\n",
    "    # < MISSING CLASS DESCRIPTION >\n",
    "    def __init__(self):\n",
    "        self.dictionary = Dictionary()\n",
    "\n",
    "    def get_data(self, path, n_gram=2):\n",
    "        with open(path, 'r') as f:\n",
    "            tokens = 0;\n",
    "            sample_list = []\n",
    "            for line in f:\n",
    "                words = ['<start>'] * n_gram + line.split() # < MISSING COMMENT >\n",
    "                tokens += len(words)\n",
    "                sample_list.append(words)\n",
    "                for word in words: \n",
    "                    self.dictionary.add_word(word)  \n",
    "        # < MISSING COMMENT FOR THE FOLLOWING PIECE OF CODE >\n",
    "        ids_list = [[0]*len(s) for s in sample_list if len(s) > n_gram] \n",
    "        with open(path, 'r') as f:\n",
    "            sample_num = 0\n",
    "            for line in f:\n",
    "                token = 0\n",
    "                words = ['<start>'] * n_gram + line.split()\n",
    "                if len(words) > n_gram:\n",
    "                    for word in words:\n",
    "                        ids_list[sample_num][token] = self.dictionary.word2idx[word]\n",
    "                        token += 1\n",
    "                    sample_num += 1\n",
    "        # < MISSING COMMENT FOR THE FOLLOWING PIECE OF CODE >\n",
    "        for n in range(len(ids_list)):\n",
    "            flat_ids = ids_list[n]\n",
    "            ids_list[n] = torch.LongTensor([flat_ids[i:i+n_gram+1] for i in range(len(flat_ids)-n_gram)])\n",
    "        return ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram = 3\n",
    "\n",
    "embed_size = 128\n",
    "intermediate_size = 1024\n",
    "num_epochs = 10\n",
    "learning_rate = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the \"Penn Treebank\" dataset and split it into train/dev/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus()\n",
    "ids = corpus.get_data('data/train_mini.txt', n_gram-1)\n",
    "train_ids = ids[:-200]\n",
    "dev_ids = ids[-200:-100]\n",
    "test_ids = ids[-100:]\n",
    "vocab_size = len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The class of n-gram language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLM(object):\n",
    "    def __init__(self, n, train_data, laplace=1):\n",
    "        self.n = n\n",
    "        self.laplace = laplace\n",
    "        self.tokens = preprocess(train_data, n)\n",
    "        self.vocab  = nltk.FreqDist(self.tokens)\n",
    "        \n",
    "        if self.n == 1:\n",
    "            num_tokens = len(self.tokens)\n",
    "            self.model = { (unigram,): count / num_tokens for unigram, count in self.vocab.items() }\n",
    "        else:\n",
    "            vocab_size = len(self.vocab)\n",
    "    \n",
    "            n_grams = nltk.ngrams(self.tokens, self.n)\n",
    "            n_vocab = nltk.FreqDist(n_grams)\n",
    "\n",
    "            self.model = { n_gram: smoothed_count(n_gram, count) for n_gram, count in n_vocab.items() }\n",
    "        \n",
    "#         self.masks  = list(reversed(list(product((0,1), repeat=n))))\n",
    "        \n",
    "    def smoothed_count(self, n_gram, n_count):\n",
    "        m_gram = n_gram[:-1]\n",
    "        m_count = m_vocab[m_gram]\n",
    "        return (n_count + self.laplace) / (m_count + self.laplace * vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "n = 2 \n",
    "model(2, train_data=train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "for i in range(0, len(test_ids)):\n",
    "    known_ngrams  = (self._convert_oov(ngram) for ngram in test_ngrams)\n",
    "    probabilities = [model[ngram] for ngram in known_ngrams]\n",
    "    print('Perplexity for test sample '+str(i)+' :', math.exp((-1/N) * sum(map(math.log, probabilities))))\n",
    "    test_ppl += np.exp(cross_entropy)\n",
    "    print('The average testing perplexity: '+str(test_ppl/len(test_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The class of neural language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, intermediate_size, n_gram):\n",
    "        super(LM, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.intermediate = nn.Linear(n_gram * embed_size, intermediate_size)\n",
    "        self.linear = nn.Linear(intermediate_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x) # < MISSING COMMENT >\n",
    "        conc_emb = x.view(x.size(0), x.size(1)*x.size(2))\n",
    "        #conc_emb = torch.cat([x[:,0,:], x[:,1,:]],1)\n",
    "        intermediate_output = self.intermediate(conc_emb) # < MISSING COMMENT >\n",
    "        final_out = self.linear(intermediate_output) # < MISSING COMMENT >\n",
    "        return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LM(vocab_size, embed_size, intermediate_size, n_gram-1).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 7.4570, Perplexity: 5247.26\n",
      "Epoch [2/10], Loss: 5.2374, Perplexity: 63173.13\n",
      "Epoch [3/10], Loss: 4.7159, Perplexity: 255881.86\n",
      "Epoch [4/10], Loss: 4.4015, Perplexity: 935003.10\n",
      "Epoch [5/10], Loss: 4.2168, Perplexity: 1637671.15\n",
      "Epoch [6/10], Loss: 4.0399, Perplexity: 4890911.58\n",
      "Epoch [7/10], Loss: 3.8980, Perplexity: 21259075.32\n",
      "Epoch [8/10], Loss: 3.7395, Perplexity: 42372702.08\n",
      "Epoch [9/10], Loss: 3.6187, Perplexity: 58546160.20\n",
      "Epoch [10/10], Loss: 3.4938, Perplexity: 185843332.48\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    avg_ppl = 0; avg_loss = 0;\n",
    "    for i in range(0, len(train_ids)):\n",
    "        inputs = train_ids[i][:, 0:n_gram-1].to(device)\n",
    "        targets = train_ids[i][:, n_gram-1:].to(device)\n",
    "        \n",
    "        # < MISSING COMMENT FOR THE FOLLOWING PIECE OF CODE >\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.reshape(-1))\n",
    "        avg_loss += loss.item();\n",
    "        \n",
    "        # < MISSING COMMENT FOR THE FOLLOWING PIECE OF CODE >\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "    \n",
    "    # < MISSING COMMENT FOR THE FOLLOWING PIECE OF CODE >\n",
    "    for i in range(0, len(dev_ids)):\n",
    "        dev_inputs = dev_ids[i][:, 0:n_gram-1].to(device)\n",
    "        dev_targets = dev_ids[i][:, n_gram-1:].to(device)\n",
    "        dev_outputs = model(dev_inputs)\n",
    "        ce = criterion(dev_outputs, dev_targets.reshape(-1))\n",
    "        avg_ppl += np.exp(ce.item());\n",
    "    \n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}'\n",
    "        .format(epoch + 1, num_epochs, avg_loss/len(train_ids), avg_ppl/len(dev_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type LM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity for test sample 0 : 5903111.050083881\n",
      "Perplexity for test sample 1 : 21729104.296588473\n",
      "Perplexity for test sample 2 : 794420922.7723972\n",
      "Perplexity for test sample 3 : 5445225407.479174\n",
      "Perplexity for test sample 4 : 10259365.496464562\n",
      "Perplexity for test sample 5 : 587957.2516781432\n",
      "Perplexity for test sample 6 : 166295.49384946204\n",
      "Perplexity for test sample 7 : 1639064.3456197989\n",
      "Perplexity for test sample 8 : 4638.557433995015\n",
      "Perplexity for test sample 9 : 85431509.58639324\n",
      "Perplexity for test sample 10 : 26697245.503057465\n",
      "Perplexity for test sample 11 : 1353401.5358296905\n",
      "Perplexity for test sample 12 : 238675.04857059504\n",
      "Perplexity for test sample 13 : 6576910.728150512\n",
      "Perplexity for test sample 14 : 1250341.257785007\n",
      "Perplexity for test sample 15 : 1545230.7107080014\n",
      "Perplexity for test sample 16 : 804875.6169132207\n",
      "Perplexity for test sample 17 : 895726.1208184625\n",
      "Perplexity for test sample 18 : 4526318.283080646\n",
      "Perplexity for test sample 19 : 666687.7637842282\n",
      "Perplexity for test sample 20 : 333739.42626094917\n",
      "Perplexity for test sample 21 : 24015940.684917655\n",
      "Perplexity for test sample 22 : 7478061.292483045\n",
      "Perplexity for test sample 23 : 92986.92372150843\n",
      "Perplexity for test sample 24 : 535110.4548430402\n",
      "Perplexity for test sample 25 : 16391386.485582609\n",
      "Perplexity for test sample 26 : 21078284366.77746\n",
      "Perplexity for test sample 27 : 1181208.9293037879\n",
      "Perplexity for test sample 28 : 11845362.227213657\n",
      "Perplexity for test sample 29 : 7219078380.295597\n",
      "Perplexity for test sample 30 : 2443531.3146399492\n",
      "Perplexity for test sample 31 : 12243025.614625778\n",
      "Perplexity for test sample 32 : 928796956.0595355\n",
      "Perplexity for test sample 33 : 19172648.902132\n",
      "Perplexity for test sample 34 : 714015.9524907079\n",
      "Perplexity for test sample 35 : 12457880.121265626\n",
      "Perplexity for test sample 36 : 309539.313431836\n",
      "Perplexity for test sample 37 : 3131921.07120239\n",
      "Perplexity for test sample 38 : 411258.4621854572\n",
      "Perplexity for test sample 39 : 1163622176.688326\n",
      "Perplexity for test sample 40 : 61228325.05700325\n",
      "Perplexity for test sample 41 : 19910104.004932944\n",
      "Perplexity for test sample 42 : 107543.67804012711\n",
      "Perplexity for test sample 43 : 49162.386195217885\n",
      "Perplexity for test sample 44 : 28121.08959107996\n",
      "Perplexity for test sample 45 : 2554508.2185580204\n",
      "Perplexity for test sample 46 : 1080071.7916906003\n",
      "Perplexity for test sample 47 : 54923253.20414905\n",
      "Perplexity for test sample 48 : 837197.6607910241\n",
      "Perplexity for test sample 49 : 15108577.13703589\n",
      "Perplexity for test sample 50 : 428724.07187806134\n",
      "Perplexity for test sample 51 : 1536362.7958046028\n",
      "Perplexity for test sample 52 : 5262988.822278863\n",
      "Perplexity for test sample 53 : 261389.59659324816\n",
      "Perplexity for test sample 54 : 1208524.1580712602\n",
      "Perplexity for test sample 55 : 20068.62247979629\n",
      "Perplexity for test sample 56 : 1351122.7819107757\n",
      "Perplexity for test sample 57 : 2503372.8698683376\n",
      "Perplexity for test sample 58 : 5845359.391529207\n",
      "Perplexity for test sample 59 : 15192813.593373016\n",
      "Perplexity for test sample 60 : 653061.8921833419\n",
      "Perplexity for test sample 61 : 4113818.428254993\n",
      "Perplexity for test sample 62 : 2145493.835225441\n",
      "Perplexity for test sample 63 : 6817123.442803087\n",
      "Perplexity for test sample 64 : 28486146.412793938\n",
      "Perplexity for test sample 65 : 44705976.4538601\n",
      "Perplexity for test sample 66 : 1393643.81852504\n",
      "Perplexity for test sample 67 : 212856820.79417154\n",
      "Perplexity for test sample 68 : 4791370.664819597\n",
      "Perplexity for test sample 69 : 354298.8083407518\n",
      "Perplexity for test sample 70 : 45693.68334421829\n",
      "Perplexity for test sample 71 : 7417496.430820504\n",
      "Perplexity for test sample 72 : 239904520.68109295\n",
      "Perplexity for test sample 73 : 5000807.029537038\n",
      "Perplexity for test sample 74 : 20416.642258295138\n",
      "Perplexity for test sample 75 : 3354448.200036602\n",
      "Perplexity for test sample 76 : 252339.07923968468\n",
      "Perplexity for test sample 77 : 1037970.0420615531\n",
      "Perplexity for test sample 78 : 18226.13304659381\n",
      "Perplexity for test sample 79 : 21422.163019166615\n",
      "Perplexity for test sample 80 : 68101.76642409131\n",
      "Perplexity for test sample 81 : 15510914.87658579\n",
      "Perplexity for test sample 82 : 201782.91100785928\n",
      "Perplexity for test sample 83 : 292636559.5913782\n",
      "Perplexity for test sample 84 : 1042355.5638929342\n",
      "Perplexity for test sample 85 : 3782832.766227401\n",
      "Perplexity for test sample 86 : 11090945.727342801\n",
      "Perplexity for test sample 87 : 407772.8729029692\n",
      "Perplexity for test sample 88 : 428724.07187806134\n",
      "Perplexity for test sample 89 : 57578730.06945573\n",
      "Perplexity for test sample 90 : 117091.11865907712\n",
      "Perplexity for test sample 91 : 116428.91586081403\n",
      "Perplexity for test sample 92 : 65833.42487021552\n",
      "Perplexity for test sample 93 : 56032.342579265336\n",
      "Perplexity for test sample 94 : 1867.8016557884116\n",
      "Perplexity for test sample 95 : 545934.7102004121\n",
      "Perplexity for test sample 96 : 284115.8877357218\n",
      "Perplexity for test sample 97 : 228195.35978092038\n",
      "Perplexity for test sample 98 : 315439.4999258034\n",
      "Perplexity for test sample 99 : 32330235.79297561\n",
      "The average testing perplexity: 380821008.66534173\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('model.ckpt')\n",
    "model.eval()\n",
    "test_ppl = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_ids)):\n",
    "        inputs = test_ids[i][:, 0:n_gram-1].to(device)\n",
    "        gold = test_ids[i][:, n_gram-1:].to(device)\n",
    "        output = model(inputs)\n",
    "        cross_entropy = criterion(output, gold.reshape(-1)).item()\n",
    "        print('Perplexity for test sample '+str(i)+' :', np.exp(cross_entropy))\n",
    "        test_ppl += np.exp(cross_entropy)\n",
    "    print('The average testing perplexity: '+str(test_ppl/len(test_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
