{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Context Free Grammar (CKY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Chomsky Normal Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rules_simplied(grammar_rules):\n",
    "    \"\"\"\n",
    "    Converts a list context-free grammar rules into the formatted Chomsky Normal Form.\n",
    "    \"\"\"\n",
    "    formatted_rules = []\n",
    "    \n",
    "#     counter = 0\n",
    "    for rule in grammar_rules:\n",
    "        \n",
    "        rule = rule.replace(\"->\", \"\").split()\n",
    "        new_rules = []\n",
    "        \n",
    "        \n",
    "        # Rule is in form A -> B C D [...] or A -> B a\n",
    "        while len(rule) > 3:\n",
    "                \n",
    "            # Create a new non-terminal symbol and replace two symbols with it\n",
    "            # This can be part of the assignment\n",
    "            new_rules.append([f\"{rule[0]}{str(counter)}\", rule[1], rule[2]])\n",
    "            rule = [rule[0]] + [f\"{rule[0]}{str(counter)}\"] + rule[3:]\n",
    "            counter += 1\n",
    "\n",
    "        # Adds a rule to the dictionary\n",
    "        formatted_rules.append(rule)\n",
    "        \n",
    "        if len(new_rules):\n",
    "            formatted_rules.extend(new_rules)\n",
    "        \n",
    "    return formatted_rules\n",
    "\n",
    "\n",
    "def convert_rules(grammar_rules):\n",
    "    \"\"\"\n",
    "    Converts a list context-free grammar rules into the formatted Chomsky Normal Form.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Stores a dictionary of lists of rules\n",
    "    rule_dict = defaultdict(list)\n",
    "    \n",
    "    unary_rules, formatted_rules = [], []\n",
    "    \n",
    "    counter = 0\n",
    "    for rule in grammar_rules:\n",
    "        \n",
    "        rule = rule.replace(\"->\", \"\").split()\n",
    "        new_rules = []\n",
    "\n",
    "        # Rule is in form A -> B, back it up for later and continue with next rule\n",
    "        if len(rule) == 2 and rule[1][0] != \"'\":\n",
    "            unary_rules.append(rule)\n",
    "            \n",
    "            # Adds a rule to the dictionary\n",
    "            rule_dict[rule[0]].append(rule[1:])\n",
    "        \n",
    "        \n",
    "        # Rule is in form A -> B C D [...] or A -> B a\n",
    "        elif len(rule) > 2:\n",
    "            \n",
    "            terminals = [(idx, item) for idx, item in enumerate(rule) if item[0] == \"'\"]\n",
    "            \n",
    "            if len(terminals):\n",
    "                for (idx, item) in terminals:\n",
    "                    \n",
    "                    # Create a new non-terminal symbol and replace the terminal symbol with it\n",
    "                    rule[idx] = f\"{rule[0]}{str(counter)}\"\n",
    "                    new_rules += [f\"{rule[0]}{str(counter)}\", item]\n",
    "                \n",
    "                counter += 1\n",
    "            \n",
    "            while len(rule) > 3:\n",
    "                \n",
    "                # Create a new non-terminal symbol and replace two symbols with it\n",
    "                new_rules.append([f\"{rule[0]}{str(counter)}\", rule[1], rule[2]])\n",
    "                rule = [rule[0]] + [f\"{rule[0]}{str(counter)}\"] + rule[3:]\n",
    "                counter += 1\n",
    "\n",
    "        # Adds a rule to the dictionary\n",
    "        rule_dict[rule[0]].append(rule[1:])\n",
    "        formatted_rules.append(rule)\n",
    "        \n",
    "        if new_rules:\n",
    "            formatted_rules.extend(new_rules)\n",
    "        \n",
    "        \n",
    "        # Recursively combine the unary rules with an existing rule (if possible)\n",
    "        while unary_rules:\n",
    "            rule = unary_rules.pop()\n",
    "            if rule[1] in rule_dict:\n",
    "                for item in rule_dict[rule1]:\n",
    "                    new_rule = [rule[0]] + item\n",
    "                    \n",
    "                    # If the new rule is binary or contains a terminal\n",
    "                    if len(new_rule) > 2 or new_rule[1][0] == \"'\":\n",
    "                        formatted_rules.insert(0, new_rule)\n",
    "                    else:\n",
    "                        unary_rules.append(new_rule)\n",
    "                    \n",
    "                    rule_dict[new_rule[0]].append(new_rule[1:])\n",
    "        \n",
    "    return formatted_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: CKY Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Barebone data structure used for storing information about a non-terminal symbol\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol, child1, child2=None):\n",
    "        self.symbol = symbol\n",
    "        self.child1 = child1\n",
    "        self.child2 = child2\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.symbol\n",
    "\n",
    "\n",
    "\n",
    "def cky_parse(text, rules):\n",
    "    \"\"\"\n",
    "    Performs Constituency Parsing using the CKY algorithm.\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    length = len(tokens)\n",
    "    \n",
    "    # Data structure for storing the subtrees\n",
    "    parse_triangle = [[[] for x in range(length - i)] for i in range(length)]\n",
    "    \n",
    "    for i, tok in enumerate(tokens):\n",
    "        \n",
    "         # Find out which non terminals can generate the terminals in the input string\n",
    "         # and put them into the parse table. One terminal could be generated by multiple\n",
    "         # non terminals, therefore the parse table will contain a list of non terminals.\n",
    "        for rule in rules:\n",
    "            if f\"'{tok}'\" == rule[1]:\n",
    "                parse_triangle[0][i].append(Node(rule[0], tok))\n",
    "    \n",
    "    # Starting from the second row\n",
    "    for row_idx in range(1, length):\n",
    "        \n",
    "        # Number of cells at each row\n",
    "        n_cells = length - row_idx\n",
    "        \n",
    "        for cell_idx in range(n_cells):\n",
    "            \n",
    "            # Number of spans being added to the cell\n",
    "            n_spans = row_idx\n",
    "            \n",
    "            for span_idx in range(n_spans):\n",
    "                \n",
    "                # This part can be part of the question!\n",
    "                left_cell = parse_triangle[span_idx][cell_idx]\n",
    "                right_cell = parse_triangle[row_idx - span_idx - 1][cell_idx + span_idx + 1]\n",
    "                \n",
    "                for rule in rules:\n",
    "                    if len(rule) == 3:\n",
    "                        \n",
    "                        # This can also be part of the question!\n",
    "                        left_nodes = list(filter(lambda n: n.symbol == rule[1], left_cell))\n",
    "                        right_nodes = list(filter(lambda n: n.symbol == rule[2], right_cell))\n",
    "                        parse_triangle[row_idx][cell_idx].extend(\n",
    "                            [Node(rule[0], left, right) for left in left_nodes for right in right_nodes]\n",
    "                        )\n",
    "\n",
    "    return parse_triangle\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Parse Sentences\n",
    "\n",
    "Ask the students to use the function print out some trees using some text input. \n",
    "\n",
    "They need to add the terminals to list of rules, and run the pipeline.\n",
    "\n",
    "Find 3 sentences where the sentences are contained in our grammar, and 3 sentences not contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree(node):\n",
    "    \"\"\"\n",
    "    Generates the string representation of the parse tree.\n",
    "    :param node: the root node.\n",
    "    :return: the parse tree in string form.\n",
    "    \"\"\"\n",
    "    if node.child2 is None:\n",
    "        return f\"[{node.symbol} '{node.child1}']\"\n",
    "    return f\"[{node.symbol} {generate_tree(node.child1)} {generate_tree(node.child2)}]\"\n",
    "\n",
    "def print_tree(parse_triangle, rules, output=True):\n",
    "    \"\"\"\n",
    "    Print the parse tree starting with the start symbol. Alternatively it returns the string\n",
    "    representation of the tree(s) instead of printing it.\n",
    "    \"\"\"\n",
    "    start_symbol = rules[0][0]\n",
    "    final_nodes = [n for n in parse_triangle[-1][0] if n.symbol == start_symbol]\n",
    "    if final_nodes:\n",
    "        if output:\n",
    "            print(\"The given sentence is contained in the language produced by the given grammar!\")\n",
    "            print(\"\\nPossible parse(s):\")\n",
    "        trees = [generate_tree(node) for node in final_nodes]\n",
    "        if output:\n",
    "            for tree in trees:\n",
    "                print(tree)\n",
    "        else:\n",
    "            return trees\n",
    "    else:\n",
    "        print(\"The given sentence is not contained in the language produced by the given grammar!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this part we can remove some rules to make the code not run... (e.g. terminals)\n",
    "grammar_rules = [\n",
    "    \"S -> NP VP\",\n",
    "    \"PP -> P NP\",\n",
    "    \"NP -> Det N\",\n",
    "    \"NP -> Det N PP\",\n",
    "    \"VP -> V NP\",\n",
    "    \"VP -> VP PP\",\n",
    "    \n",
    "    # Example of a terminal (use single quotation marks)\n",
    "    \"N -> 'school'\",\n",
    "    \n",
    "    # Your rules here ...\n",
    "    \"NP -> 'I'\",\n",
    "    \"Det -> 'an'\",\n",
    "    \"Det -> 'my'\",\n",
    "    \"N -> 'elephant'\",\n",
    "    \"N -> 'pajamas'\",\n",
    "    \"V -> 'shot'\",\n",
    "    \"P -> 'in'\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solutions for Q3\n",
    "normalized_rules = convert_rules_simplied(grammar_rules)\n",
    "parsed_triangle = cky_parse(\"I shot an elephant in my pajamas\", rules)\n",
    "print_tree(parse_triangle, rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
