{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: PCFG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "predefined_grammar = {\n",
    "    \"S -> NP VP\":   0.5,\n",
    "    \"VP -> V NP\":   0.5,\n",
    "    \"VP -> VP PP\":  0.5,\n",
    "    \"PP -> P NP\":   1,\n",
    "    \"NP -> NP PP\":  0.25,\n",
    "    \"NP -> John\":   0.25,\n",
    "    \"NP -> soccer\": 0.25,\n",
    "    \"NP -> school\": 0.25,\n",
    "    \"V -> plays\":   1,\n",
    "    \"P -> at\":      1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def format_rules(grammar_rules):\n",
    "    \"\"\"\n",
    "    The following function converts the grammar rules to the form used by our parser\n",
    "    \"\"\"\n",
    "    formatted_rules = []\n",
    "    probilities = defaultdict(lambda: None)\n",
    "    for rule, prob in grammar_rules.items():\n",
    "        \n",
    "        rule = tuple(rule.replace(\"->\", \"\").split())\n",
    "        probilities[rule] = prob\n",
    "        \n",
    "        # Adds a rule to the dictionary\n",
    "        formatted_rules.append(rule)\n",
    "        \n",
    "    return formatted_rules, probilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: CKY Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Barebone data structure used for storing information about a non-terminal symbol\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol, prob, child1, child2=None):\n",
    "        self.symbol = symbol\n",
    "        self.prob = prob\n",
    "        self.child1 = child1\n",
    "        self.child2 = child2\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.symbol\n",
    "\n",
    "\n",
    "\n",
    "def cky_parse(text, rules, probabilities):\n",
    "    \"\"\"\n",
    "    Performs Constituency Parsing using the CKY algorithm.\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    length = len(tokens)\n",
    "    \n",
    "    # Data structure for storing the subtrees\n",
    "    parse_triangle = [[[] for x in range(length - i)] for i in range(length)]\n",
    "    \n",
    "    for i, tok in enumerate(tokens):\n",
    "        \n",
    "         # Find out which non terminals can generate the terminals in the input string\n",
    "         # and put them into the parse table. One terminal could be generated by multiple\n",
    "         # non terminals, therefore the parse table will contain a list of non terminals.\n",
    "        for rule in rules:\n",
    "            if tok == rule[1]:\n",
    "                \n",
    "                prob = probabilities[rule]\n",
    "                parse_triangle[0][i].append(Node(rule[0], prob, tok))\n",
    "    \n",
    "    # Starting from the second row\n",
    "    for row_idx in range(1, length):\n",
    "        \n",
    "        # Number of cells at each row\n",
    "        n_cells = length - row_idx\n",
    "        \n",
    "        for cell_idx in range(n_cells):\n",
    "            \n",
    "            # Number of spans being added to the cell\n",
    "            n_spans = row_idx\n",
    "            \n",
    "            for span_idx in range(n_spans):\n",
    "                \n",
    "                left_cell = parse_triangle[span_idx][cell_idx]\n",
    "                right_cell = parse_triangle[row_idx - span_idx - 1][cell_idx + span_idx + 1]\n",
    "                max_prob, max_prob_node = 0, None\n",
    "\n",
    "                for rule in rules:\n",
    "                    if len(rule) == 3:\n",
    "                        rule_prob = probabilities[rule]\n",
    "                        left_nodes = list(filter(lambda n: n.symbol == rule[1], left_cell))\n",
    "                        right_nodes = list(filter(lambda n: n.symbol == rule[2], right_cell))\n",
    "                        if len(left_nodes) and len(right_nodes):\n",
    "                            nodes = [Node(rule[0], rule_prob * left.prob * right.prob, left, right) \\\n",
    "                                         for left in left_nodes for right in right_nodes]\n",
    "                            max_node = max(nodes, key=lambda x: x.prob)\n",
    "                            if max_node.prob > max_prob:\n",
    "                                max_prob = max_node.prob\n",
    "                                max_prob_node = max_node\n",
    "                            \n",
    "                if max_prob_node != None:\n",
    "                    parse_triangle[row_idx][cell_idx].append(max_prob_node)\n",
    "\n",
    "    return parse_triangle\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Constructing (and Visualizing) Parsed Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree(node):\n",
    "    \"\"\"\n",
    "    Generates the string representation of the parse tree.\n",
    "    :param node: the root node.\n",
    "    :return: the parse tree in string form.\n",
    "    \"\"\"\n",
    "    if node.child2 is None:\n",
    "        return f\"[{node.symbol} '{node.child1}']\"\n",
    "    return f\"[{node.symbol} {generate_tree(node.child1)} {generate_tree(node.child2)}]\"\n",
    "\n",
    "def construct_and_print_tree(parse_triangle, start_symbol=\"S\", round_digits=6):\n",
    "    \"\"\"\n",
    "    Print the parse tree starting with the start symbol, using the Node pointers to backtrack.\n",
    "    \"\"\"\n",
    "    final_nodes = [n for n in parse_triangle[-1][0] if n.symbol == start_symbol]\n",
    "    if final_nodes:\n",
    "        prob = round(final_nodes[0].prob, round_digits)\n",
    "        print(f\"The given sentence is contained in the language produced by the given grammar with probability: {prob}\")\n",
    "        trees = [generate_tree(node) for node in final_nodes]\n",
    "        for tree in trees:\n",
    "            print(tree)\n",
    "    else:\n",
    "        print(\"The given sentence is not contained in the language produced by the given grammar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(text, rules):\n",
    "    \"\"\"\n",
    "    This wrapper function parse the given `text` using `rules` with CKY,\n",
    "    and print out the parsed tree with the highest probability.\n",
    "    \n",
    "    You can use this for your solution.\n",
    "    \"\"\"\n",
    "    rules, probs = format_rules(rules)\n",
    "    parse_triangle = cky_parse(text, rules, probs)\n",
    "    construct_and_print_tree(parse_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given sentence is contained in the language produced by the given grammar with probability: 0.001953\n",
      "[S [NP 'John'] [VP [VP [V 'plays'] [NP 'soccer']] [PP [P 'at'] [NP 'school']]]]\n",
      "\n",
      "The given sentence is contained in the language produced by the given grammar with probability: 0.004544\n",
      "[S [NP 'John'] [VP [VP [V 'plays'] [NP 'soccer']] [PP [P 'at'] [NP 'school']]]]\n",
      "\n",
      "The given sentence is not contained in the language produced by the given grammar!\n",
      "\n",
      "The given sentence is not contained in the language produced by the given grammar!\n"
     ]
    }
   ],
   "source": [
    "# For solution (probilistic grammar computed from silly corpus)\n",
    "text = \"John plays soccer at school\"\n",
    "text2 = \"John plays\"\n",
    "\n",
    "computed_grammar = None\n",
    "\n",
    "# This is from my 503 assignment\n",
    "computed_grammar = {\n",
    "    \"S -> NP VP\":   1.0,\n",
    "    \"VP -> V NP\":   10/13,\n",
    "    \"VP -> VP PP\":  3/13,\n",
    "    \"PP -> P NP\":   1.0,\n",
    "    \"NP -> NP PP\":  0.04,\n",
    "    \"NP -> John\":   0.4,\n",
    "    \"NP -> soccer\": 0.4,\n",
    "    \"NP -> school\": 0.16,\n",
    "    \"V -> plays\":   1.0,\n",
    "    \"P -> at\":      1.0,\n",
    "}\n",
    "\n",
    "parse_text(text, predefined_grammar)\n",
    "print(\"\")\n",
    "\n",
    "parse_text(text, computed_grammar)\n",
    "print(\"\")\n",
    "\n",
    "parse_text(text2, predefined_grammar)\n",
    "print(\"\")\n",
    "\n",
    "parse_text(text2, computed_grammar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
